{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"R_HOME\"] = \"/root/miniconda3/envs/R/lib/R\"\n",
    "\n",
    "import rpy2.robjects as objects\n",
    "from rpy2.robjects.packages import importr\n",
    "\n",
    "base = importr(\"base\")\n",
    "r_pROC = importr(\"pROC\")\n",
    "base._libPaths()[0]\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifr = pd.read_csv(\n",
    "    \"../CathAI/data/DeepCORO/CathReport_MHI_Merged/2017-2021_CathReport_first_value_in_interval_IFR.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define column where IFR was performed\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def create_new_col(df):\n",
    "    # List of column names to be checked\n",
    "    col_names = [\n",
    "        \"D2\",\n",
    "        \"D3\",\n",
    "        \"RVG1\",\n",
    "        \"RVG2\",\n",
    "        \"S1\",\n",
    "        \"Saph√®ne ou mammaire\",\n",
    "        \"bx\",\n",
    "        \"diagonal\",\n",
    "        \"dist_lad\",\n",
    "        \"dist_lcx\",\n",
    "        \"dist_rca\",\n",
    "        \"lad\",\n",
    "        \"lcx\",\n",
    "        \"leftmain\",\n",
    "        \"lvp\",\n",
    "        \"marg_d\",\n",
    "        \"mid_lad\",\n",
    "        \"mid_rca\",\n",
    "        \"om1\",\n",
    "        \"om2\",\n",
    "        \"om3\",\n",
    "        \"pda\",\n",
    "        \"posterolateral\",\n",
    "        \"prox_rca\",\n",
    "    ]\n",
    "\n",
    "    # Iterating over rows using DataFrame.apply() and lambda function\n",
    "    df[\"ifr_performed\"] = df.apply(\n",
    "        lambda row: \", \".join([col for col in col_names if row[col] != -1.0]), axis=1\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_new_col(df_ifr)\n",
    "df[\"contains_lad\"] = df[\"ifr_performed\"].str.contains(\"lad\")\n",
    "df[\"contains_lcx\"] = df[\"ifr_performed\"].str.contains(\"lcx\")\n",
    "df[\"contains_rca\"] = df[\"ifr_performed\"].str.contains(\"rca|pda|posterolateral\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ifr.head(n=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge with DICOMS Extracted\n",
    "\n",
    "df_dicoms = pd.read_csv(\n",
    "    \"../CathAI/data/DeepCORO/EXAMS_Extracted/2017-2021_dicom_extracted_mod.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify common columns in df and df_dicoms, excluding 'path'\n",
    "common_cols = [col for col in df.columns if col in df_dicoms.columns and col != \"path\"]\n",
    "\n",
    "# Drop common columns from df_dicoms\n",
    "df_dicoms_dropped = df_dicoms.drop(columns=common_cols)\n",
    "\n",
    "# Perform left merge\n",
    "df_merged = pd.merge(\n",
    "    df, df_dicoms_dropped, left_on=\"DICOMPath\", right_on=\"path\", how=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merge with views\n",
    "df_angle_object = pd.read_csv(\n",
    "    \"../CathAI/data/DeepCORO/CATHAI_Extracted_Concatenated/DeepCORO_df_angle_object_dicom_2017-2021.csv\"\n",
    ")\n",
    "### Drop Unnamed columns\n",
    "df_angle_object = df_angle_object.loc[\n",
    "    :, ~df_angle_object.columns.str.contains(\"^Unnamed\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform left merge\n",
    "df_merged_angle_object = pd.merge(df_merged, df_angle_object, on=\"path\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_merged_angle_object.object_value.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_merged_angle_object.contains_lad.value_counts())\n",
    "display(df_merged_angle_object.contains_lcx.value_counts())\n",
    "display(df_merged_angle_object.contains_rca.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1425 examens avec IFR dans IVA, LCX ou RCA\n",
    "display(df_f.grou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_f.to_csv(\"data/df_f.csv\", index=False)\n",
    "df_merged_angle_object.to_csv(\"data/df_merged_angle_object_IFR.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure, here's a markdown table based on the labels' definitions:\n",
    "\n",
    "| Label | Name         | 'primary' range | 'secondary' range |\n",
    "|-------|--------------|-----------------|-------------------|\n",
    "| 0     | RAO Cranial  | -60 to -15      | 15 to 50          |\n",
    "| 1     | AP Cranial   | -15 to 15       | 15 to 50          |\n",
    "| 2     | LAO Cranial  | 15 to 60        | 15 to 50          |\n",
    "| 3     | RAO Straight | -60 to -15      | -15 to 15         |\n",
    "| 4     | AP           | -15 to 15       | -15 to 15         |\n",
    "| 5     | LAO Straight | 15 to 60        | -15 to 15         |\n",
    "| 6     | RAO Caudal   | -60 to -15      | -50 to -15        |\n",
    "| 7     | AP Caudal    | -15 to 15       | -50 to -15        |\n",
    "| 8     | LAO Caudal   | 15 to 60        | -50 to -15        |\n",
    "| 9     | LAO Lateral  | -110 to -70     | -15 to 15         |\n",
    "| 10    | RAO Lateral  | 70 to 110       | -15 to 15         |\n",
    "| 11    | Other        | Not applicable  | Not applicable    |\n",
    "\n",
    "Note: The ranges in the 'primary' and 'secondary' columns are inclusive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "from downloadAvi import extract_avi_metadata as avi_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_f = pd.read_csv(\"data/df_f.csv\")\n",
    "df_merged_angle_object = pd.read_csv(\"data/df_merged_angle_object_IFR.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered = df_merged_angle_object[\n",
    "    (df_merged_angle_object[\"contains_lad\"] == True)\n",
    "    | (df_merged_angle_object[\"contains_lcx\"] == True)\n",
    "    | (df_merged_angle_object[\"contains_rca\"] == True)\n",
    "]\n",
    "df_filtered.to_csv(\"data/df_merged_angle_object_IFR_performed_2017-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avi_meta.extract_avi_and_metadata(\n",
    "    \"data/df_merged_angle_object_IFR_performed_2017-2021.csv\",\n",
    "    data_type=\"ANGIO\",\n",
    "    destinationFolder=\"deepIFR/\",\n",
    "    dataFolder=\"data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview Videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_labels(df, primary, secondary, label_column, label2_column):\n",
    "    label_list = []\n",
    "    label2_list = []\n",
    "    for _, row in tqdm(df.iterrows()):\n",
    "        p = row[primary]\n",
    "        s = row[secondary]\n",
    "        if (-60 <= p <= -15) and (15 <= s <= 50):\n",
    "            label_list.append(0)\n",
    "            label2_list.append(\"RAO Cranial\")\n",
    "        elif (-15 <= p <= 15) and (15 <= s <= 50):\n",
    "            label_list.append(1)\n",
    "            label2_list.append(\"AP Cranial\")\n",
    "        elif (15 <= p <= 60) and (15 <= s <= 50):\n",
    "            label_list.append(2)\n",
    "            label2_list.append(\"LAO Cranial\")\n",
    "        elif (-60 <= p <= -15) and (-15 <= s <= 15):\n",
    "            label_list.append(3)\n",
    "            label2_list.append(\"RAO Straight\")\n",
    "        elif (-15 <= p <= 15) and (-15 <= s <= 15):\n",
    "            label_list.append(4)\n",
    "            label2_list.append(\"AP\")\n",
    "        elif (15 <= p <= 60) and (-15 <= s <= 15):\n",
    "            label_list.append(5)\n",
    "            label2_list.append(\"LAO Straight\")\n",
    "        elif (-60 <= p <= -15) and (-50 <= s <= -15):\n",
    "            label_list.append(6)\n",
    "            label2_list.append(\"RAO Caudal\")\n",
    "        elif (-15 <= p <= 15) and (-50 <= s <= -15):\n",
    "            label_list.append(7)\n",
    "            label2_list.append(\"AP Caudal\")\n",
    "        elif (15 <= p <= 60) and (-50 <= s <= -15):\n",
    "            label_list.append(8)\n",
    "            label2_list.append(\"LAO Caudal\")\n",
    "        elif (-110 <= p <= -70) and (-15 <= s <= 15):\n",
    "            label_list.append(9)\n",
    "            label2_list.append(\"LAO Lateral\")\n",
    "        elif (70 <= p <= 110) and (-15 <= s <= 15):\n",
    "            label_list.append(10)\n",
    "            label2_list.append(\"RAO Lateral\")\n",
    "        else:\n",
    "            label_list.append(11)\n",
    "            label2_list.append(\"Other\")\n",
    "\n",
    "    df[label_column] = label_list\n",
    "    df[label2_column] = label2_list\n",
    "    return df\n",
    "\n",
    "\n",
    "def convert_seconds_to_time(df, time_column, new_time_column):\n",
    "    \"\"\"\n",
    "    Converts the specified column from seconds to datetime format.\n",
    "\n",
    "    Parameters:\n",
    "    df : DataFrame\n",
    "        The DataFrame which contains the column to be converted.\n",
    "    time_column : str\n",
    "        The name of the column to be converted.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame\n",
    "        The DataFrame with the converted column.\n",
    "    \"\"\"\n",
    "    df[new_time_column] = pd.to_timedelta(df[time_column], unit=\"s\")\n",
    "    return df\n",
    "\n",
    "\n",
    "def format_time(df, time_column):\n",
    "    \"\"\"\n",
    "    Formats the specified timedelta column to 'hh:mm:ss' format.\n",
    "\n",
    "    Parameters:\n",
    "    df : DataFrame\n",
    "        The DataFrame which contains the column to be formatted.\n",
    "    time_column : str\n",
    "        The name of the column to be formatted.\n",
    "\n",
    "    Returns:\n",
    "    DataFrame\n",
    "        The DataFrame with the formatted column.\n",
    "    \"\"\"\n",
    "    df[time_column] = (\n",
    "        df[time_column]\n",
    "        .dt.components[[\"hours\", \"minutes\", \"seconds\"]]\n",
    "        .astype(str)\n",
    "        .agg(\":\".join, axis=1)\n",
    "    )\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifr_videos = pd.read_csv(\"data/df_merged_angle_object_IFR_performed_2017-2021.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifr_videos.loc[df_ifr_videos[\"series_time\"] < 0, \"series_time\"] = None\n",
    "df_ifr_videos = convert_seconds_to_time(\n",
    "    df_ifr_videos, \"series_time\", \"series_time_human\"\n",
    ")\n",
    "df_ifr_videos = format_time(df_ifr_videos, \"series_time_human\")\n",
    "\n",
    "df_ifr_videos.loc[df_ifr_videos[\"study_time\"] < 0, \"study_time\"] = None\n",
    "df_ifr_videos = convert_seconds_to_time(df_ifr_videos, \"study_time\", \"study_time_human\")\n",
    "df_ifr_videos = format_time(df_ifr_videos, \"study_time_human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifr_metadata = pd.read_csv(\n",
    "    \"data/df_merged_angle_object_IFR_performed_2017-2021.csv_metadata_extracted.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merged df_ifr_videos and df_ifr_metadata on dicom_path and path but remove from df_ifr_metadata the column StudyInstanceUID\n",
    "df_ifr_metadata = df_ifr_metadata.drop(\n",
    "    columns=[\"StudyInstanceUID\", \"series_time\", \"study_time\"]\n",
    ")\n",
    "df_ifr_videos_metadata = pd.merge(\n",
    "    df_ifr_videos, df_ifr_metadata, right_on=\"dicom_path\", left_on=\"path\", how=\"inner\"\n",
    ")\n",
    "\n",
    "## Remove columns starting with Unnamed df_ifr_videos_metadata\n",
    "df_ifr_videos_metadata = df_ifr_videos_metadata.loc[\n",
    "    :, ~df_ifr_videos_metadata.columns.str.contains(\"^Unnamed\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ifr_videos_metadata = create_labels(\n",
    "    df_ifr_videos_metadata,\n",
    "    \"primary_angle\",\n",
    "    \"secondary_angle\",\n",
    "    \"angle_true_label\",\n",
    "    \"angle_true_string_label\",\n",
    ")\n",
    "df_ifr_videos_metadata.to_csv(\n",
    "    \"data/df_merged_angle_object_IFR_performed_2017_with_metadata_and_angles.csv\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_ifr_videos_metadata.angle_value.value_counts())\n",
    "display(df_ifr_videos_metadata.angle_true_label.value_counts())\n",
    "display(df_ifr_videos_metadata.angle_true_string_label.value_counts())\n",
    "display(df_ifr_videos_metadata.object_value.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Select first 3 videos for RCA :\n",
    "## For LAD select view AP Cranial, LAO Cranial or RAO Cranial\n",
    "## For LCX sleect view RAO Straight, LAO Caudal, RAO Caudal, AP Caudal\n",
    "\n",
    "### Generate videos\n",
    "\n",
    "## Now create a function  taking a dataframe in and processing it as follows : where if the column [‚Äòcontains_rca‚Äô] is True then select first three rows for each ‚ÄúExamID‚Äù;\n",
    "## If the column [‚Äòcontain_lad‚Äô] is True, then select first three rows based on the earliest [‚Äô series_time‚Äô]   for each ‚ÄúExamID‚Äù where ‚Äúangle_true_string_label‚Äù is either \"AP Cranial, LAO Cranial or RAO Cranial ‚Äú and ‚Äúobject_vlaue‚Äù is 5.0\n",
    "### if [‚Äòcontains_lcx‚Äô] is True then select first three rows based on the earliest [‚Äô series_time‚Äô] where ‚Äúangle_true_string_label‚Äù is either \"RAO Straight, LAO Caudal, RAO Caudal, AP Caudal ‚Äú and ‚Äúobject_vlaue‚Äù is 5.0.\n",
    "\n",
    "\n",
    "def process_dataframe(df):\n",
    "    # Replace .0 and convert to timedelta\n",
    "    # df['series_time'] = pd.to_timedelta(df['series_time'].str.replace('.0', ''))\n",
    "\n",
    "    # df['series_time'] = pd.to_datetime(df['series_time'])\n",
    "\n",
    "    # if 'contains_rca' is True then select first three rows based on the earliest 'series_time' for each ‚ÄúExamID‚Äù\n",
    "    rca_df = (\n",
    "        df[(df[\"contains_rca\"] == True) & (df[\"object_value\"] == 9.0)]\n",
    "        .groupby(\"ExamID\")\n",
    "        .apply(lambda x: x.nsmallest(3, \"series_time\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # if 'contain_lad' is True, then select first three rows based on the earliest 'series_time'\n",
    "    lad_conditions = (\n",
    "        (df[\"contains_lad\"] == True)\n",
    "        & (\n",
    "            df[\"angle_true_string_label\"].isin(\n",
    "                [\"AP Cranial\", \"LAO Cranial\", \"RAO Cranial\"]\n",
    "            )\n",
    "        )\n",
    "        & (df[\"object_value\"] == 5.0)\n",
    "    )\n",
    "    lad_df = (\n",
    "        df.loc[lad_conditions]\n",
    "        .groupby(\"ExamID\")\n",
    "        .apply(lambda x: x.nsmallest(3, \"series_time\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # if 'contains_lcx' is True then select first three rows based on the earliest 'series_time'\n",
    "    lcx_conditions = (\n",
    "        (df[\"contains_lcx\"] == True)\n",
    "        & (\n",
    "            df[\"angle_true_string_label\"].isin(\n",
    "                [\"RAO Straight\", \"LAO Caudal\", \"RAO Caudal\", \"AP Caudal\"]\n",
    "            )\n",
    "        )\n",
    "        & (df[\"object_value\"] == 5.0)\n",
    "    )\n",
    "    lcx_df = (\n",
    "        df.loc[lcx_conditions]\n",
    "        .groupby(\"ExamID\")\n",
    "        .apply(lambda x: x.nsmallest(3, \"series_time\"))\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "    # concatenate all dataframes\n",
    "    result_df = pd.concat([rca_df, lad_df, lcx_df])\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = process_dataframe(df_ifr_videos_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.to_csv('data/df_merged_angle_object_IFR_performed_2017_with_metadata_and_angles_processed_filtered_3_videos.csv')\n",
    "# exploded_df.to_csv('data/exploded_df_merged_angle_object_IFR_performed_2017_with_metadata_and_angles_processed_filtered_3_videos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = pd.read_csv(\n",
    "    \"data/df_merged_angle_object_IFR_performed_2017_with_metadata_and_angles_processed_filtered_3_videos.csv\"\n",
    ")\n",
    "display(result_df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "from IPython.display import HTML, Video, display\n",
    "from ipywidgets import interactive\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Create a temporary directory\n",
    "temp_dir = tempfile.TemporaryDirectory()\n",
    "\n",
    "# Select the first ExamID\n",
    "exam_id = result_df[\"ExamID\"].iloc[3300]\n",
    "\n",
    "# Select the corresponding rows\n",
    "rows = result_df[result_df[\"ExamID\"] == exam_id]\n",
    "video_data = rows[[\"FileName\", \"angle_true_string_label\", \"ifr_performed\"]].values\n",
    "\n",
    "# Convert .avi to .mp4 and save them in the temporary directory\n",
    "for i in range(len(video_data)):\n",
    "    clip = VideoFileClip(video_data[i][0])\n",
    "    new_video_path = os.path.join(temp_dir.name, f\"video_{i}.mp4\")\n",
    "    clip.write_videofile(new_video_path, codec=\"libx264\")\n",
    "    video_data[i][0] = new_video_path\n",
    "\n",
    "\n",
    "def play_video(index):\n",
    "    video_path, angle_label, ifr_performed = video_data[index]\n",
    "    ifr_performed = ifr_performed.split(\",\")[\n",
    "        0\n",
    "    ]  # pick only the first value when multiple values are present\n",
    "    ifr_value = rows.iloc[index][ifr_performed]\n",
    "    display(\n",
    "        HTML(f\"<h2>Angle: {angle_label}, IFR: {ifr_performed}, Value: {ifr_value}</h2>\")\n",
    "    )\n",
    "    display(Video(video_path, embed=True))\n",
    "\n",
    "\n",
    "video_player = interactive(play_video, index=(0, len(video_data) - 1))\n",
    "\n",
    "display(video_player)  # Manually display the widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When you're done with the videos, you can clean up the temporary directory\n",
    "temp_dir.cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(result_df.iloc[3300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that your `result_df` DataFrame and the corresponding `ifr_performed` column look something like this:\n",
    "\n",
    "```\n",
    "| FileName | ifr_performed        | posterolateral | prox_rca |\n",
    "|----------|----------------------|----------------|----------|\n",
    "| video_1  | posterolateral       | 1.2            | 0.9      |\n",
    "| video_2  | prox_rca             | 1.1            | 1.0      |\n",
    "| video_3  | posterolateral,prox_rca | 1.3            | 1.1      |\n",
    "```\n",
    "\n",
    "And you want to end up with a DataFrame like this:\n",
    "\n",
    "```\n",
    "| FileName | ifr_performed | ifr  |\n",
    "|----------|---------------|------|\n",
    "| video_1  | posterolateral| 1.2  |\n",
    "| video_2  | prox_rca      | 1.0  |\n",
    "| video_3  | posterolateral| 1.3  |\n",
    "| video_3  | prox_rca      | 1.1  |\n",
    "```\n",
    "\n",
    "You can achieve this with the following code:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# This is a helper function to explode rows with multiple IFR performed\n",
    "def explode_row(row):\n",
    "    ifrs = row['ifr_performed'].split(',')\n",
    "    for ifr in ifrs:\n",
    "        new_row = row.copy()\n",
    "        new_row['ifr_performed'] = ifr.strip()  # Removing any potential leading/trailing spaces\n",
    "        new_row['ifr'] = row[ifr.strip()]      # Retrieving the corresponding value\n",
    "        exploded_rows.append(new_row)\n",
    "\n",
    "# Create an empty list to hold the exploded rows\n",
    "exploded_rows = []\n",
    "\n",
    "# Iterate over each row in the original DataFrame\n",
    "result_df.apply(explode_row, axis=1)\n",
    "\n",
    "# Create a new DataFrame from the list of exploded rows\n",
    "exploded_df = pd.DataFrame(exploded_rows)\n",
    "\n",
    "# Reset the index\n",
    "exploded_df.reset_index(drop=True, inplace=True)\n",
    "```\n",
    "\n",
    "Now `exploded_df` is a new DataFrame where each row represents a unique video-segment where IFR was performed, with a new column `ifr` that stores the value of the corresponding IFR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# This is a helper function to explode rows with multiple IFR performed\n",
    "\n",
    "\n",
    "def explode_row(row):\n",
    "    ifrs = row[\"ifr_performed\"].split(\",\")\n",
    "    for ifr in ifrs:\n",
    "        new_row = row.copy()\n",
    "        new_row[\n",
    "            \"ifr_performed\"\n",
    "        ] = ifr.strip()  # Removing any potential leading/trailing spaces\n",
    "        new_row[\"ifr\"] = row[ifr.strip()]  # Retrieving the corresponding value\n",
    "        exploded_rows.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to hold the exploded rows\n",
    "exploded_rows = []\n",
    "\n",
    "# Iterate over each row in the original DataFrame\n",
    "result_df.apply(explode_row, axis=1)\n",
    "\n",
    "# Create a new DataFrame from the list of exploded rows\n",
    "exploded_df = pd.DataFrame(exploded_rows)\n",
    "\n",
    "# Reset the index\n",
    "exploded_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()\n",
    "\n",
    "\n",
    "display(df_stats(exploded_df))\n",
    "display(df_stats(result_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exploded_df.ifr.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
