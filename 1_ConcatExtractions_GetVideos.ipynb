{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_54454/1667009573.py:9: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def list_files(dir):\n",
    "    r = []\n",
    "    subdirs = [x[0] for x in os.walk(dir)]\n",
    "    for subdir in subdirs:\n",
    "        files = os.walk(subdir).__next__()[2]\n",
    "\n",
    "        if len(files) > 0:\n",
    "            for file in files:\n",
    "                r.append(os.path.join(subdir, file))\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = list_files(\"/media/data1/ravram/DeepOCT_Abbott\")\n",
    "#display(len(r), \" files found\")\n",
    "#df = pd.DataFrame(list(zip(r)), columns=[\"path\"])\n",
    "#new_2 = df[\"path\"].str.split(\"/\", n=8, expand=True)\n",
    "\n",
    "#df[\"StudyInstanceUID\"] = new_2[6]\n",
    "#df[\"patient_id\"] = new_2[5]\n",
    "#df[\"dicom_id\"] = new_2[7]\n",
    "#display(df.head(n=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../Oread/data_Maher/XA_00019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../Oread/data_Maher/XA_00018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../Oread/data_Maher/XA_00015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>../Oread/data_Maher/XA_00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>../Oread/data_Maher/XA_00006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>../Oread/data_Maher/XA_00009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>../Oread/data_Maher/XA_00003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>../Oread/data_Maher/XA_00013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>../Oread/data_Maher/XA_00008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>../Oread/data_Maher/XA_00002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>../Oread/data_Maher/XA_00020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>../Oread/data_Maher/XA_00023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>../Oread/data_Maher/XA_00014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>../Oread/data_Maher/XA_00011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>../Oread/data_Maher/XA_00004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>../Oread/data_Maher/XA_00017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>../Oread/data_Maher/XA_00016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>../Oread/data_Maher/XA_00021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>../Oread/data_Maher/XA_00007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>../Oread/data_Maher/XA_00001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>../Oread/data_Maher/XA_00010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>../Oread/data_Maher/XA_00022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>../Oread/data_Maher/XA_00012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            path\n",
       "0   ../Oread/data_Maher/XA_00019\n",
       "1   ../Oread/data_Maher/XA_00018\n",
       "4   ../Oread/data_Maher/XA_00015\n",
       "6   ../Oread/data_Maher/XA_00005\n",
       "7   ../Oread/data_Maher/XA_00006\n",
       "8   ../Oread/data_Maher/XA_00009\n",
       "9   ../Oread/data_Maher/XA_00003\n",
       "11  ../Oread/data_Maher/XA_00013\n",
       "12  ../Oread/data_Maher/XA_00008\n",
       "14  ../Oread/data_Maher/XA_00002\n",
       "15  ../Oread/data_Maher/XA_00020\n",
       "19  ../Oread/data_Maher/XA_00023\n",
       "20  ../Oread/data_Maher/XA_00014\n",
       "22  ../Oread/data_Maher/XA_00011\n",
       "23  ../Oread/data_Maher/XA_00004\n",
       "24  ../Oread/data_Maher/XA_00017\n",
       "26  ../Oread/data_Maher/XA_00016\n",
       "28  ../Oread/data_Maher/XA_00021\n",
       "29  ../Oread/data_Maher/XA_00007\n",
       "34  ../Oread/data_Maher/XA_00001\n",
       "41  ../Oread/data_Maher/XA_00010\n",
       "44  ../Oread/data_Maher/XA_00022\n",
       "46  ../Oread/data_Maher/XA_00012"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r = list_files(\"../Oread/data_Maher\")\n",
    "df = pd.DataFrame(list(zip(r)), columns=[\"path\"])\n",
    "df = df.loc[df[\"path\"].str.contains(\"XA\")]\n",
    "display(df)\n",
    "df.to_csv('data_Maher.csv')\n",
    "\n",
    "#new_2 = df[\"path\"].str.split(\"/\", n=8, expand=True)\n",
    "\n",
    "#df[\"StudyInstanceUID\"] = new_2[6]\n",
    "#df[\"patient_id\"] = new_2[5]\n",
    "#df[\"dicom_id\"] = new_2[7]\n",
    "#display(df.head(n=15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted = pd.read_csv(\"data/Abbott_OCT/database-c-find_ABBOTT.csv\")\n",
    "df_extracted = pd.DataFrame({\"path\": r})\n",
    "df_extracted[\"FileType\"] = df_extracted.path.apply(lambda x: x.split(\".\")[-1])\n",
    "display(\"Total files\", df_extracted.FileType.value_counts())\n",
    "\n",
    "df_extracted = df_extracted.loc[df_extracted[\"FileType\"] == \"dcm\"]\n",
    "new_2 = df_extracted[\"path\"].str.split(\"/\", n=7, expand=True)\n",
    "\n",
    "df_extracted[\"mrn\"] = new_2[5]\n",
    "df_extracted[\"StudyInstanceUID\"] = new_2[6]\n",
    "df_extracted[\"dicom_id\"] = new_2[7].str.rstrip(\".dcm\")\n",
    "df_extracted_study_level = (\n",
    "    df_extracted.groupby([\"mrn\", \"StudyInstanceUID\"]).first().reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_m = pd.merge(\n",
    "    df_extracted_study_level.drop(columns={\"dicom_id\", \"path\"}),\n",
    "    df,\n",
    "    how=\"inner\",\n",
    "    on=[\"StudyInstanceUID\"],\n",
    ")\n",
    "display(\n",
    "    df_extracted_m.loc[\n",
    "        df_extracted_m[\"dicom_id\"]\n",
    "        == \"1.3.12.2.1107.5.4.5.135214.30000022072511311760100000156.dcm\"\n",
    "    ]\n",
    ")\n",
    "df_extracted_m.to_csv(\"data/Abbott_OCT/df_extracted_m_ABBOTT.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_m = pd.read_csv(\"data/Abbott_OCT/df_extracted_m_ABBOTT.csv\")\n",
    "display(\n",
    "    df_extracted_m.loc[\n",
    "        df_extracted_m[\"StudyInstanceUID\"] == \"2.16.124.113611.1.118.1.1.5884039\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract AVI Metadata\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "< cv2.VideoWriter 0x7f459fb834d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'dicom_avi_extracted/data_Maher_XA_00019.avi'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DICOMPath doesn't exist\n",
      "1 ../Oread/data_Maher/XA_00019\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) /io/opencv/modules/videoio/src/cap_ffmpeg.cpp:192: error: (-215:Assertion failed) image.depth() == CV_8U in function 'write'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdownloadAvi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extract_avi_metadata \u001b[38;5;28;01mas\u001b[39;00m avi_meta\n\u001b[0;32m----> 3\u001b[0m \u001b[43mavi_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_avi_and_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata_Maher.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/volume/DicomVideoProcessing/downloadAvi/extract_avi_metadata.py:441\u001b[0m, in \u001b[0;36mextract_avi_and_metadata\u001b[0;34m(path, data_type, destinationFolder, dataFolder)\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;28mprint\u001b[39m(count, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    439\u001b[0m     os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(destinationFolder, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m][row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mrindex(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.avi\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    440\u001b[0m ):\n\u001b[0;32m--> 441\u001b[0m     dicom_metadata \u001b[38;5;241m=\u001b[39m \u001b[43mmakeVideo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mVideoPath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdestinationFolder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dicom_metadata, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    443\u001b[0m         final_list\u001b[38;5;241m.\u001b[39mappend(dicom_metadata)\n",
      "File \u001b[0;32m/volume/DicomVideoProcessing/downloadAvi/extract_avi_metadata.py:280\u001b[0m, in \u001b[0;36mmakeVideo\u001b[0;34m(fileToProcess, destinationFolder, datatype)\u001b[0m\n\u001b[1;32m    276\u001b[0m display(video_filename)\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m testarray:\n\u001b[0;32m--> 280\u001b[0m     \u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m out\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    282\u001b[0m dicom_dict \u001b[38;5;241m=\u001b[39m dicom_dataset_to_dict(dataset, fileToProcess)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/videoio/src/cap_ffmpeg.cpp:192: error: (-215:Assertion failed) image.depth() == CV_8U in function 'write'\n"
     ]
    }
   ],
   "source": [
    "from downloadAvi import extract_avi_metadata as avi_meta\n",
    "\n",
    "avi_meta.extract_avi_and_metadata(\"data_Maher.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"data_Maher.csv\")\n",
    "\n",
    "dataset = dicom.dcmread(df.path.iloc[0], force=True)\n",
    "\n",
    "testarray = dataset.pixel_array\n",
    "testarray = np.stack((testarray,) * 3, axis=-1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Plot images for each class for the OBJECT RECON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "This code will create a 1x11 subplot with each subplot showing the middle frame from a random video of the corresponding class. The title of each subplot is the class name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import choice\n",
    "\n",
    "# Let's assume df is your dataframe with columns 'FileName' and 'Class'\n",
    "\n",
    "def plot_middle_frames(df):\n",
    "    classes = df['y_true_cat'].unique()\n",
    "    fig, axs = plt.subplots(3, 4, figsize=(20, 20))\n",
    "\n",
    "    for i, cls in enumerate(classes):\n",
    "        # Select a random sample from each class\n",
    "        sample = df[df['y_true_cat'] == cls].sample(1).iloc[0]\n",
    "        video_path = sample['FileName']\n",
    "\n",
    "        # Load the video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "        # Get the number of frames\n",
    "        num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "        # Select the middle frame\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, num_frames // 2)\n",
    "\n",
    "        # Read the middle frame\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Plot the frame\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        axs[row, col].imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        axs[row, col].set_title(cls)\n",
    "        axs[row, col].axis('off')  # Hide axes\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "2f394aca7ca06fed1e6064aef884364492d7cdda3614a461e02e6407fc40ba69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
