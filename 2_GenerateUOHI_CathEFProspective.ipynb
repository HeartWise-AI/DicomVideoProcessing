{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import os\n",
    "\n",
    "\n",
    "def df_stats(df):\n",
    "    from tabulate import tabulate\n",
    "\n",
    "    print(\"\\n***** Shape: \", df.shape, \" *****\\n\")\n",
    "\n",
    "    columns_list = df.columns.values.tolist()\n",
    "    isnull_list = df.isnull().sum().values.tolist()\n",
    "    isunique_list = df.nunique().values.tolist()\n",
    "    dtypes_list = df.dtypes.tolist()\n",
    "\n",
    "    list_stat_val = list(zip(columns_list, isnull_list, isunique_list, dtypes_list))\n",
    "    df_stat_val = pd.DataFrame(\n",
    "        list_stat_val, columns=[\"Name\", \"Null\", \"Unique\", \"Dtypes\"]\n",
    "    )\n",
    "    print(tabulate(df_stat_val, headers=\"keys\", tablefmt=\"psql\"))\n",
    "    return df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_dcm_files(directory):\n",
    "    dcm_files = []\n",
    "\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith(\".dcm\"):\n",
    "                full_path = os.path.join(root, file)\n",
    "                dcm_files.append(full_path)\n",
    "\n",
    "    return dcm_files\n",
    "\n",
    "\n",
    "# Use the function\n",
    "directory = \"/media/data1/ravram/CathEF_UOHI/\"\n",
    "dcm_files = find_dcm_files(directory)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_cathEF_UOHI = pd.DataFrame(dcm_files, columns=[\"path\"])\n",
    "# df_cathEF_UOHI.to_csv('data/CathEF_Prospective/df_files_UOHI.csv')\n",
    "\n",
    "# Use the function\n",
    "directory = \"/media/data1/ravram/CathEF_Prospective/\"\n",
    "dcm_files = find_dcm_files(directory)\n",
    "\n",
    "\n",
    "# Create a DataFrame\n",
    "df_cathEF_MHI = pd.DataFrame(dcm_files, columns=[\"path\"])\n",
    "# df_cathEF_MHI.to_csv('data/CathEF_Prospective/df_files_MHI.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Generate videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# pd.set_option('display.height', 1000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.width\", 1000)\n",
    "pd.set_option(\"max_colwidth\", 200)\n",
    "from IPython.core.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "from downloadAvi import extract_avi_metadata as avi_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "directory = \"../Oread/CathEF_Prospective/\"\n",
    "avi_files = [file for file in os.listdir(directory) if file.endswith(\".avi\")]\n",
    "num_avi_files = len(avi_files)\n",
    "\n",
    "print(f\"Number of .avi files: {num_avi_files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/df_files_MHI_UOHI_concat.csv\")\n",
    "# Rename df['dicom_path'] to ['path']\n",
    "df.rename(columns={\"dicom_path\": \"path\"}, inplace=True)\n",
    "display(df.head(n=5))\n",
    "# display(df.head(n=5))\n",
    "\n",
    "df.to_csv(\"data/df_files_MHI_UOHI_concat.csv\")\n",
    "# row = df[df['FileName'].str.contains('2.16.124.113611.1.118.1.1.6506117_1.3.46.670589.29.1877192777354251333053229336874672.dcm.avi')]\n",
    "# row.to_csv('data/df_files_MHI_UOHI_concat_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "avi_meta.extract_avi_and_metadata(\n",
    "    \"data/df_files_MHI_UOHI_concat.csv\",\n",
    "    data_type=\"ANGIO\",\n",
    "    destinationFolder=\"CathEF_Prospective/\",\n",
    "    dataFolder=\"data/\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cathEF_UOHI = pd.read_csv(\"data/df_files_UOHI.csv_metadata_extracted.csv\")\n",
    "df_cathEF_MHI = pd.read_csv(\"data/df_files_MHI.csv_metadata_extracted.csv\")\n",
    "\n",
    "df_extracted = pd.read_csv(\n",
    "    \"../pydicom-batch/data/audit-inference-20210803-20230803_extract.csv\"\n",
    ")\n",
    "df_extracted = df_extracted.groupby([\"StudyInstanceUID\"]).first().reset_index()\n",
    "df_extracted_merged = pd.merge(\n",
    "    df_extracted.groupby([\"StudyInstanceUID\"]).first().reset_index(),\n",
    "    df_cathEF_MHI,\n",
    "    how=\"right\",\n",
    "    on=\"StudyInstanceUID\",\n",
    ")\n",
    "# Rename df_extracted_merged['mrn'] to ['PatientID_anon']\n",
    "df_extracted_merged.rename(columns={\"mrn\": \"PatientID_anon\"}, inplace=True)\n",
    "# Rename df_extracted_merged['PatientID'] to ['mrn']\n",
    "df_extracted_merged.rename(columns={\"PatientID\": \"mrn\"}, inplace=True)\n",
    "\n",
    "df_extracted_concat = pd.concat([df_extracted_merged, df_cathEF_UOHI])\n",
    "\n",
    "display(df_extracted_concat.describe())\n",
    "df_extracted_concat.to_csv(\"data/df_files_MHI_UOHI_concat.csv\")\n",
    "display(df_extracted_concat.head(n=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_extracted_merged.to_csv('data/CathEF_inference-20231016_FINAL.csv_metadata_extracted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save df_extracted_merged with mu separator\n",
    "# df_extracted_merged.to_csv('data/CathEF_inference-20231016_FINAL.csv_metadata_extracted_mu.csv', sep='µ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def copy_files_with_progress(\n",
    "    df_extracted_merged, dest_folder=\"../Oread/CathEF_Prospective/\"\n",
    "):\n",
    "    # Count and print the number of files in the destination folder before copy\n",
    "    pre_copy_count = len(os.listdir(dest_folder))\n",
    "    print(f\"Number of files in destination folder before copy: {pre_copy_count}\")\n",
    "\n",
    "    # Iterate through file names in the DataFrame and copy them\n",
    "    for src_path in tqdm(df_extracted_merged[\"FileName\"]):\n",
    "        file_name = os.path.basename(src_path)\n",
    "        dest_path = os.path.join(dest_folder, file_name)\n",
    "\n",
    "        if os.path.exists(src_path):\n",
    "            shutil.copy(src_path, dest_path)\n",
    "\n",
    "    # Count and print the number of files in the destination folder after copy\n",
    "    post_copy_count = len(os.listdir(dest_folder))\n",
    "    print(f\"Number of files in destination folder after copy: {post_copy_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_merged = pd.read_csv(\n",
    "    \"data/df_files_MHI_UOHI_concat.csv_metadata_extracted.csv\"\n",
    ")\n",
    "# Drop NaN for df_extracted_merged['dicom_path']\n",
    "df_extracted_merged.dropna(subset=[\"dicom_path\"], inplace=True)\n",
    "display(df_extracted_merged.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copy_files_with_progress(\n",
    "    df_extracted_merged, dest_folder=\"../Oread/CathEF_Prospective/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_extracted_merged = pd.read_csv(\n",
    "    \"data/df_files_MHI_UOHI_concat.csv_metadata_extracted.csv\"\n",
    ")\n",
    "# Drop NaN for df_extracted_merged['dicom_path']\n",
    "df_extracted_merged.dropna(subset=[\"dicom_path\"], inplace=True)\n",
    "\n",
    "# REname df_extracted_merged['mrn'] to ['PatientID']\n",
    "df_extracted_merged.rename(columns={\"mrn\": \"PatientID\"}, inplace=True)\n",
    "display(df_extracted_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_extract = pd.read_csv(\"data/df_files_MHI_UOHI_concat.csv\")\n",
    "display(df_pre_extract.head(n=5))\n",
    "df_pre_extract = df_pre_extract[[\"mrn\", \"PatientID_anon\"]]\n",
    "df_pre_extract_merged = df_pre_extract.groupby([\"PatientID_anon\"]).first().reset_index()\n",
    "df_extracted_merged_m = pd.merge(\n",
    "    df_extracted_merged,\n",
    "    df_pre_extract_merged,\n",
    "    how=\"left\",\n",
    "    left_on=\"PatientID\",\n",
    "    right_on=\"PatientID_anon\",\n",
    ")\n",
    "## Np.where df_extracted_merged_m['mrn'] is present keep df_extracted_merged_m['PatientID'] is equal to mrn else keep df_extracted_merged_m['PatientID']\n",
    "df_extracted_merged_m[\"PatientID\"] = np.where(\n",
    "    df_extracted_merged_m[\"mrn\"].notnull(),\n",
    "    df_extracted_merged_m[\"mrn\"],\n",
    "    df_extracted_merged_m[\"PatientID\"],\n",
    ")\n",
    "display(df_extracted_merged_m.PatientID.nunique())\n",
    "df_extracted_merged_m.to_csv(\"data/df_files_MHI_UOHI_concat_mrn_fixed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uohi_extracted = pd.read_csv(\"data/df_files_UOHI.csv_metadata_extracted.csv\")\n",
    "display(df_uohi_extracted.describe())\n",
    "df_uohi_extracted = pd.read_csv(\"data/df_files_MHI.csv_metadata_extracted.csv\")\n",
    "display(df_uohi_extracted.describe())\n",
    "# df_uohi_extracted = pd.read_csv('data/df_files_UOHI.csv_metadata_extracted_mu.csv', sep='µ')\n",
    "# display(df_uohi_extracted.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
